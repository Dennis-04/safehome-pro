import streamlit as st
import time  # <--- ì´ ì¤„ì´ ë¹ ì ¸ìˆì–´ì„œ ë‚œ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ì¶”ê°€í•´ì£¼ì„¸ìš”!
from datetime import datetime
from openai import OpenAI # ë‚˜ì¤‘ì— í”„ë¡¬í”„íŠ¸ ê°•í™” ë•Œ ì‚¬ìš©í•  ì¤€ë¹„

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SafeHome 3D - ì†”ë£¨ì…˜", page_icon="ğŸ§¸", layout="wide")

# 2. [ë””ìì¸] R4X ë¡œë´‡ ë°°ê²½
st.markdown("""
<style>
    .stApp { background: transparent !important; }
    header, footer { visibility: hidden !important; }
    #spline-bg { position: fixed; top: 0; left: 0; width: 100vw; height: 100vh; z-index: 0; border: none; }
    .block-container { position: relative; z-index: 1; padding-top: 5vh; max-width: 800px; }

    /* ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .stChatMessage {
        background: rgba(0, 0, 0, 0.7);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255,255,255,0.2);
        border-radius: 15px;
        margin-bottom: 10px;
    }
    /* ìœ ì € ë©”ì‹œì§€ */
    div[data-testid="chatAvatarIcon-user"] { background-color: #38bdf8; }
    /* AI ë©”ì‹œì§€ */
    div[data-testid="chatAvatarIcon-assistant"] { background-color: #f43f5e; }
    
    h1 { text-shadow: 0 0 20px rgba(255,255,255,0.5); }
</style>
<iframe id="spline-bg" src='https://my.spline.design/r4xbot-x144J8ISm6Am5vnam9xXxwah/' frameborder='0'></iframe>
""", unsafe_allow_html=True)

# 3. ë©”ì¸ UI
st.title("ğŸ¤– AI Concierge Link")
st.caption("ê±°ì£¼ ì¤‘ ë°œìƒí•˜ëŠ” ë²•ì  ë¬¸ì œ, ìˆ˜ë¦¬ ìš”ì²­ ë“± ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì‹œìŠ¤í…œ ì˜¨ë¼ì¸. R4X ë´‡ì…ë‹ˆë‹¤. \n\në³´ì¼ëŸ¬ ê³ ì¥, ì¸µê°„ ì†ŒìŒ, ì›”ì„¸ ì¸ìƒ ìš”êµ¬ ë“± ê³¤ë€í•œ ì¼ì´ ìˆìœ¼ì‹ ê°€ìš”?"}
    ]

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# ì…ë ¥ì°½
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë³´ì¼ëŸ¬ê°€ ê³ ì¥ ë‚¬ëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ê³ ì³ì¤˜ìš”)"):
    # 1. ìœ ì € ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    # 2. AI ì‘ë‹µ (ë‚˜ì¤‘ì— ë¡œì§ ê°•í™”í•  ë¶€ë¶„)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # [ì‹œë®¬ë ˆì´ì…˜] ë‚˜ì¤‘ì— ì‹¤ì œ GPT ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ êµì²´ë  ë¶€ë¶„
        simulated_response = "í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë¯¼ë²• ì œ623ì¡°ì— ë”°ë¥´ë©´ ì„ëŒ€ì¸ì€ ëª©ì ë¬¼ì„ ì‚¬ìš©, ìˆ˜ìµí•˜ê²Œ í•  ì˜ë¬´ê°€ ìˆìœ¼ë¯€ë¡œ ë³´ì¼ëŸ¬ ìˆ˜ë¦¬ëŠ” ì›ì¹™ì ìœ¼ë¡œ ì§‘ì£¼ì¸ì˜ ì˜ë¬´ì…ë‹ˆë‹¤. \n\nì§‘ì£¼ì¸ì—ê²Œ ë³´ë‚¼ ë¬¸ì ì´ˆì•ˆì„ ì‘ì„±í•´ ë“œë¦´ê¹Œìš”?"
        
        # íƒ€ì´í•‘ íš¨ê³¼ ì—°ì¶œ
        for chunk in simulated_response.split():
            full_response += chunk + " "
            time.sleep(0.05)
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
        
    st.session_state.messages.append({"role": "assistant", "content": full_response})